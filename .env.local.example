# ============================================
# AutoCognitix - Local Development Environment
# ============================================
# Copy this file to .env for local development with Docker Compose
# This file uses LOCAL services (not cloud) for development
#
# SECURITY WARNING: NEVER commit your actual .env file!
# Generate secure passwords with: openssl rand -hex 32

# ============================================
# PostgreSQL (Local Docker)
# ============================================
POSTGRES_USER=autocognitix
POSTGRES_PASSWORD=dev_password_change_me
POSTGRES_DB=autocognitix
DATABASE_URL=postgresql+asyncpg://autocognitix:dev_password_change_me@localhost:5432/autocognitix

# ============================================
# Neo4j (Local Docker)
# ============================================
NEO4J_USER=neo4j
NEO4J_PASSWORD=dev_password_change_me
NEO4J_URI=bolt://localhost:7687

# ============================================
# Qdrant (Local Docker)
# ============================================
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_GRPC_PORT=6334
# For local development, no API key needed
# QDRANT_URL and QDRANT_API_KEY are only needed for Qdrant Cloud

# ============================================
# Redis (Local Docker)
# ============================================
REDIS_URL=redis://localhost:6379/0

# ============================================
# Application Configuration
# ============================================
# IMPORTANT: Generate a real secret for any non-local use!
SECRET_KEY=local_dev_secret_key_not_for_production_use
DEBUG=true
ENVIRONMENT=development

# API Settings
API_V1_PREFIX=/api/v1
PROJECT_NAME=AutoCognitix
BACKEND_CORS_ORIGINS=["http://localhost:3000","http://localhost:8000"]

# ============================================
# JWT Configuration
# ============================================
# IMPORTANT: JWT_SECRET_KEY must be at least 32 characters!
# For production, generate with: openssl rand -hex 32
JWT_SECRET_KEY=local_dev_jwt_secret_minimum_32_chars
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# ============================================
# External API Keys
# ============================================
# NHTSA API (free, no key required)
NHTSA_API_BASE_URL=https://vpic.nhtsa.dot.gov/api

# ============================================
# LLM Configuration
# ============================================
# For local development, you can use:
# 1. Ollama (free, runs locally)
# 2. Groq (free tier available)
# 3. Anthropic/OpenAI (paid)

LLM_PROVIDER=ollama

# Ollama (free, local) - recommended for development
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Groq (free tier) - get key from https://console.groq.com
# GROQ_API_KEY=your_groq_api_key_here

# Anthropic (paid) - uncomment if using
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# OpenAI (paid) - uncomment if using
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4-turbo-preview

# ============================================
# Back4App (Vehicle Database)
# ============================================
# Get credentials from: https://www.back4app.com/database/back4app/car-make-model-dataset
# Optional - GitHub fallback will be used if not configured
# BACK4APP_APP_ID=your_back4app_app_id_here
# BACK4APP_API_KEY=your_back4app_api_key_here

# ============================================
# Hungarian NLP Configuration
# ============================================
HUBERT_MODEL=SZTAKI-HLT/hubert-base-cc
EMBEDDING_DIMENSION=768
HUSPACY_MODEL=hu_core_news_lg

# ============================================
# Logging Configuration
# ============================================
LOG_LEVEL=DEBUG
LOG_FORMAT=json

# ============================================
# Rate Limiting
# ============================================
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000
